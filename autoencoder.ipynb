{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32,[None,28,28,1])\n",
    "targets_ = tf.placeholder(tf.float32,[None,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x,alpha=0.1):\n",
    "    return tf.maximum(alpha*x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Encoder\n",
    "with tf.name_scope('encoder'):\n",
    "    conv1 = tf.layers.conv2d(inputs_,filters=64,kernel_size=(3,3),strides=(1,1),padding='SAME',use_bias=True,activation=relu,name='conv1')\n",
    "# Now 28x28x64\n",
    "    maxpool1 = tf.layers.max_pooling2d(conv1,pool_size=(2,2),strides=(2,2),name='pool1')\n",
    "# Now 14x14x64\n",
    "    conv2 = tf.layers.conv2d(maxpool1,filters=64,kernel_size=(3,3),strides=(1,1),padding='SAME',use_bias=True,activation=relu,name='conv2')\n",
    "# Now 14x14x64\n",
    "    encoded = tf.layers.max_pooling2d(conv2,pool_size=(2,2),strides=(2,2),name='encoding')\n",
    "# Now 7x7x64.\n",
    "#latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Decoder\n",
    "with tf.name_scope('decoder'):\n",
    "    conv3 = tf.layers.conv2d_transpose(encoded,filters=64,kernel_size=3,padding='same',strides=2,name='conv3')\n",
    "#Now 14x14x64        \n",
    "    conv4 = tf.layers.conv2d(conv3,filters=64,kernel_size=(3,3),strides=(1,1),padding='SAME',use_bias=True,activation=relu,name='upsample1')\n",
    "# Now 14x14x64\n",
    "    conv5 = tf.layers.conv2d_transpose(conv4,filters=64,kernel_size=3,padding='same',strides=2,name='upsample2')\n",
    "# Now 28x28x64\n",
    "    logits = tf.layers.conv2d(conv5,filters=1,kernel_size=(3,3),strides=(1,1),name='logits',padding='SAME',use_bias=True)\n",
    "#Now 28x28x1\n",
    "# Pass logits through sigmoid to get reconstructed image\n",
    "    decoded = tf.sigmoid(logits,name='recon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=targets_)\n",
    "\n",
    "learning_rate=tf.placeholder(tf.float32)\n",
    "cost = tf.reduce_mean(loss)  #cost\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost) #optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "sess = tf.Session()\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "loss = []\n",
    "valid_loss = []\n",
    "\n",
    "\n",
    "\n",
    "display_step = 1\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "lr=1e-5 #learning rate\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter('./graphs', sess.graph)\n",
    "for e in range(epochs):\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    for ibatch in range(total_batch):\n",
    "        #feed train and validation image each batch (original noise-free image)\n",
    "        batch_x = mnist.train.next_batch(batch_size)\n",
    "        batch_test_x= mnist.test.next_batch(batch_size)\n",
    "        #reshape train and validation image\n",
    "        #print(batch_x[0].shape)\n",
    "        #print(batch_x[0])\n",
    "        imgs = batch_x[0].reshape((-1, 28, 28, 1))\n",
    "        imgs_test = batch_x[0].reshape((-1, 28, 28, 1))\n",
    "        #define noise factor\n",
    "        noise_factor = 0.5\n",
    "        #add noise to train image\n",
    "        x_train_noisy = imgs + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=imgs.shape) \n",
    "        x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "        #add noise to validation image\n",
    "        x_test_noisy = imgs_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=imgs_test.shape) \n",
    "        x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "        \n",
    "        #training, feed train image with noise as input\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: x_train_noisy,\n",
    "                                                         targets_: imgs,learning_rate:lr})\n",
    "        #validation, feed validation image with noise as input\n",
    "        batch_cost_test = sess.run(cost, feed_dict={inputs_: x_test_noisy,\n",
    "                                                         targets_: imgs_test})\n",
    "    #show training loss and validation loss each epoch\n",
    "    if (e+1) % display_step == 0:\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Training loss: {:.4f}\".format(batch_cost),\n",
    "                 \"Validation loss: {:.4f}\".format(batch_cost_test))\n",
    "    \n",
    "    #plot training loss and validation loss\n",
    "    loss.append(batch_cost)\n",
    "    valid_loss.append(batch_cost_test)\n",
    "    plt.plot(range(e+1), loss, 'b', label='Training loss')\n",
    "    plt.plot(range(e+1), valid_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs ',fontsize=16)\n",
    "    plt.ylabel('Loss',fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "     \n",
    "\n",
    "#test 10 images\n",
    "batch_x= mnist.test.next_batch(10)\n",
    "imgs = batch_x[0].reshape((-1, 28, 28, 1))\n",
    "noise_factor = 0.5\n",
    "x_test_noisy = imgs + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=imgs.shape) \n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "recon_img = sess.run([decoded], feed_dict={inputs_: x_test_noisy})[0]\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.title('Reconstructed Images')\n",
    "\n",
    "#show original noise-free image\n",
    "print(\"Original Images\")\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(imgs[i, ..., 0], cmap='gray')\n",
    "plt.show()    \n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "#show noisy image\n",
    "print(\"Noisy Images\")\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(x_test_noisy[i, ..., 0], cmap='gray')\n",
    "plt.show()    \n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "#show image after reconstruction of noisy\n",
    "print(\"Reconstruction of Noisy Images\")\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(recon_img[i, ..., 0], cmap='gray')    \n",
    "plt.show()    \n",
    "\n",
    "writer.close()\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
